{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8c637c",
   "metadata": {},
   "source": [
    "### Imports and setup\n",
    "* Imports text ML and evaluation tools\n",
    "* Downloads linguistic resources(stopword, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc268dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\himu7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\himu7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import string\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066df33b",
   "metadata": {},
   "source": [
    "### Load Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05eec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (44898, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>title_length</th>\n",
       "      <th>date_parsed</th>\n",
       "      <th>year_month</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: GOP Chairman Grassley Has Had Enough, DEMANDS Trump Jr. Testimony</td>\n",
       "      <td>Donald Trump s White House is in chaos, and they are trying to cover it up. Their Russia problems are mounting by the hour, and they refuse to acknowledge that there are problems surrounding all of this. To them, it s  fake news,  or a  hoax.  However, the facts bear things out differently, and ...</td>\n",
       "      <td>News</td>\n",
       "      <td>July 21, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2114</td>\n",
       "      <td>76</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>2017-07</td>\n",
       "      <td>BREAKING: GOP Chairman Grassley Has Had Enough, DEMANDS Trump Jr. Testimony Donald Trump s White House is in chaos, and they are trying to cover it up. Their Russia problems are mounting by the hour, and they refuse to acknowledge that there are problems surrounding all of this. To them, it s  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Failed GOP Candidates Remembered In Hilarious Mocking Eulogies (VIDEO)</td>\n",
       "      <td>Now that Donald Trump is the presumptive GOP nominee, it s time to remember all those other candidates who tried so hard to beat him in the race to the White House. After all, how can we forget all the missteps, gaffes, weirdness, and sheer idiocies of such candidates as Jeb Bush, Marco Rubio, J...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 7, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2823</td>\n",
       "      <td>71</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>2016-05</td>\n",
       "      <td>Failed GOP Candidates Remembered In Hilarious Mocking Eulogies (VIDEO) Now that Donald Trump is the presumptive GOP nominee, it s time to remember all those other candidates who tried so hard to beat him in the race to the White House. After all, how can we forget all the missteps, gaffes, weir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          title  \\\n",
       "0   BREAKING: GOP Chairman Grassley Has Had Enough, DEMANDS Trump Jr. Testimony   \n",
       "1        Failed GOP Candidates Remembered In Hilarious Mocking Eulogies (VIDEO)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          text  \\\n",
       "0  Donald Trump s White House is in chaos, and they are trying to cover it up. Their Russia problems are mounting by the hour, and they refuse to acknowledge that there are problems surrounding all of this. To them, it s  fake news,  or a  hoax.  However, the facts bear things out differently, and ...   \n",
       "1  Now that Donald Trump is the presumptive GOP nominee, it s time to remember all those other candidates who tried so hard to beat him in the race to the White House. After all, how can we forget all the missteps, gaffes, weirdness, and sheer idiocies of such candidates as Jeb Bush, Marco Rubio, J...   \n",
       "\n",
       "  subject           date  label  text_length  title_length date_parsed  \\\n",
       "0    News  July 21, 2017      0         2114            76  2017-07-21   \n",
       "1    News    May 7, 2016      0         2823            71  2016-05-07   \n",
       "\n",
       "  year_month  \\\n",
       "0    2017-07   \n",
       "1    2016-05   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                       content  \n",
       "0   BREAKING: GOP Chairman Grassley Has Had Enough, DEMANDS Trump Jr. Testimony Donald Trump s White House is in chaos, and they are trying to cover it up. Their Russia problems are mounting by the hour, and they refuse to acknowledge that there are problems surrounding all of this. To them, it s  ...  \n",
       "1   Failed GOP Candidates Remembered In Hilarious Mocking Eulogies (VIDEO) Now that Donald Trump is the presumptive GOP nominee, it s time to remember all those other candidates who tried so hard to beat him in the race to the White House. After all, how can we forget all the missteps, gaffes, weir...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/combined_news.csv\")\n",
    "print(\"Data Shape:\", df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76406e0d",
   "metadata": {},
   "source": [
    "### Basic Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffbab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    23481\n",
       "1    21417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd521a5",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273a3fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (35918,)\n",
      "Test size:  (8980,)\n"
     ]
    }
   ],
   "source": [
    "X = df[\"content\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "print(\"Train size: \", X_train.shape)\n",
    "print(\"Test size: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8591558",
   "metadata": {},
   "source": [
    "### Define Preprocessing Functions\n",
    "\n",
    "* `clean_basic()` is to normalize the text by converting everything to lowercase and removing URLs and HTML tage, which are noise for NLP models.\n",
    "\n",
    "* `clean_no_punct()` is to remove punctuation so symbols like commas or exclamation marks don't get treated as features.\n",
    "\n",
    "* `clean_no_stopwords()` is to split text into words, remove stopwords like the, is And andm and then join the remaining meaningful words back into a sentence.\n",
    "\n",
    "*  `clean_lemmatized()` is to lemmatize each word, converting words like running to run and cars to car, which reduces vocabulary size and imporoves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4878b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_basic(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def clean_no_punct(text):\n",
    "    text = clean_basic(text)\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "def clean_no_stopwords(text):\n",
    "    text = clean_no_punct(text)\n",
    "    tokens = text.split()\n",
    "    return \" \".join([t for t in tokens if t not in stop_words])\n",
    "\n",
    "def clean_lemmatized(text):\n",
    "    text = clean_no_stopwords(text)\n",
    "    tokens = text.split()\n",
    "    return \" \".join([lemmatizer.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e93a6",
   "metadata": {},
   "source": [
    "### Apply Preprocessing Variants\n",
    "\n",
    "Applying text cleaning functions to the training and testing dataset to create multiple cleaned version on the same text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea21e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basis = X_train.apply(clean_basic)\n",
    "X_test_basis = X_test.apply(clean_basic)\n",
    "\n",
    "X_train_nonpunct = X_train.apply(clean_no_punct)\n",
    "X_test_nopunct = X_test.apply(clean_no_punct)\n",
    "\n",
    "X_train_nostop = X_train.apply(clean_no_stopwords)\n",
    "X_test_nostop = X_test.apply(clean_no_stopwords)\n",
    "\n",
    "X_train_lemma = X_train.apply(clean_lemmatized)\n",
    "X_test_lemma = X_test.apply(clean_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb79d4",
   "metadata": {},
   "source": [
    "### Tf-Idf Vectorizzer\n",
    "\n",
    "Configured a TF-IDF vectorizer to convert text into numerical features while controlling noise and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96eddcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df = 5, \n",
    "    max_df = 0.95, \n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d0a77",
   "metadata": {},
   "source": [
    "### Define Models to Compare\n",
    "\n",
    "Created a dictionary of different machine-learning models so we can train and compare them easily using the same data.\n",
    "\n",
    "* `Naive Bayes` because it is fast, simple, and works well with TF-IDF features for text classification.\n",
    "* `Logistic Regression` because it has higher iteration limit to ensure proper convergence on higher-dimensional text data.\n",
    "* `SVM` because it is strong for text classificationi and often performs well with sparse, high-dimensional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eac9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": LinearSVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cc2dd",
   "metadata": {},
   "source": [
    "### Evaluation Function\n",
    "\n",
    "Writing this function to train, evaluate and compare multiple models using a specific preprocessing strategy. \n",
    "\n",
    "First print the preprocessing label so we know which text-cleaning version is being evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33344e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(Xtr, Xte, ytr, yte, label):\n",
    "    print(f\"\\n------ Preprocessing: {label} ------\")\n",
    "\n",
    "    Xtr_vec = vectorizer.fit_transform(Xtr)\n",
    "    Xte_vec = vectorizer.transform(Xte)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(Xtr_vec, ytr)\n",
    "        preds = model.predict(Xte_vec)\n",
    "        f1 = f1_score(yte, preds)\n",
    "        scores[name] = f1\n",
    "        print(f\"{name} : F1-score: {f1:.4f}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a272e3",
   "metadata": {},
   "source": [
    "### Run Experiments \n",
    "\n",
    "Create a reults dictionary to store model performance for different text-preprocessing strategies. For each preprocessing method(basic cleaning, no punctuatoin, no stopwords and lemmatization), this is called `evaluate_models` function using the corresponding cleaned training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Preprocessing: Basic Cleaning ------\n",
      "Naive Bayes : F1-score: 0.9575\n",
      "Logistic Regression : F1-score: 0.9903\n",
      "Linear SVM : F1-score: 0.9967\n",
      "\n",
      "------ Preprocessing: No Punctuation ------\n",
      "Naive Bayes : F1-score: 0.9580\n",
      "Logistic Regression : F1-score: 0.9909\n",
      "Linear SVM : F1-score: 0.9961\n",
      "\n",
      "------ Preprocessing: No Stopwords ------\n",
      "Naive Bayes : F1-score: 0.9653\n",
      "Logistic Regression : F1-score: 0.9920\n",
      "Linear SVM : F1-score: 0.9979\n",
      "\n",
      "------ Preprocessing: Lemmatized ------\n",
      "Naive Bayes : F1-score: 0.9660\n",
      "Logistic Regression : F1-score: 0.9919\n",
      "Linear SVM : F1-score: 0.9977\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "results[\"Basic\"] = evaluate_models(\n",
    "    X_train_basis, X_test_basis, y_train, y_test, \"Basic Cleaning\"\n",
    ")\n",
    "\n",
    "results[\"No Punctuation\"] = evaluate_models(\n",
    "    X_train_nonpunct, X_test_nopunct, y_train, y_test, \"No Punctuation\"\n",
    ")\n",
    "\n",
    "results[\"No Stopwords\"] = evaluate_models(\n",
    "    X_train_nostop, X_test_nostop, y_train, y_test, \"No Stopwords\"\n",
    ")\n",
    "\n",
    "results[\"Lemmatizer\"] = evaluate_models(\n",
    "    X_train_lemma, X_test_lemma, y_train, y_test, \"Lemmatized\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3eadc0",
   "metadata": {},
   "source": [
    "### Visualtization :\n",
    "* Bar chart per processing method\n",
    "* Overall comparison heatmap (best for analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aae822",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df.T."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
